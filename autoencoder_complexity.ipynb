{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.models\n",
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "numeros = sklearn.datasets.load_digits()\n",
    "imagenes = numeros['images']  # Hay 1797 digitos representados en imagenes 8x8\n",
    "n_imagenes = len(imagenes)\n",
    "X = imagenes.copy()\n",
    "Y = numeros['target']\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.autograd.Variable(torch.Tensor(X).float()).unsqueeze(1)\n",
    "print(inputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# muestra algunos ejemplos\n",
    "\n",
    "n_items = inputs.data.size()[0]\n",
    "random_items = np.random.choice(np.arange(n_items), 5)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    item  = random_items[i]\n",
    "    plt.imshow(inputs[item][0].detach().numpy())\n",
    "    plt.title(Y[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1797, 1, 8, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normaliza\n",
    "mean = inputs.mean(dim=0)\n",
    "std = inputs.std(dim=0)\n",
    "std[std==0]=1.0\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    inputs[i] = (inputs[i])/std\n",
    "np.shape(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=3),\n",
    "            torch.nn.Conv2d(16,8,kernel_size=3),\n",
    "            torch.nn.Conv2d(8,4,kernel_size=3))\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(4,8,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(8,16,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(16,1,kernel_size=3))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self,k1, k2, k3):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        #k1=16; k2=8; k3=4\n",
    "        self.k1=k1\n",
    "        self.k2=k2\n",
    "        self.k3=k3\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, k1, kernel_size=3),\n",
    "            torch.nn.Conv2d(k1,k2,kernel_size=3),\n",
    "            torch.nn.Conv2d(k2,k3,kernel_size=3))\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(k3,k2,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(k2,k1,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(k1,1,kernel_size=3))\n",
    "    def forward(self,x,k1, k2, k3):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-403d29e2fe28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# inicializa modelo, loss y optimizador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k2' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ConvTranspose2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "epoch [1/100], loss:2.4360\n",
      "epoch [2/100], loss:2.2727\n",
      "epoch [3/100], loss:2.0557\n",
      "epoch [4/100], loss:1.7871\n",
      "epoch [5/100], loss:1.6233\n",
      "epoch [6/100], loss:1.7040\n",
      "epoch [7/100], loss:1.5177\n",
      "epoch [8/100], loss:1.3956\n",
      "epoch [9/100], loss:1.3682\n",
      "epoch [10/100], loss:1.3512\n",
      "epoch [11/100], loss:1.3108\n",
      "epoch [12/100], loss:1.2503\n",
      "epoch [13/100], loss:1.1903\n",
      "epoch [14/100], loss:1.1552\n",
      "epoch [15/100], loss:1.1401\n",
      "epoch [16/100], loss:1.1089\n",
      "epoch [17/100], loss:1.0631\n",
      "epoch [18/100], loss:1.0309\n",
      "epoch [19/100], loss:1.0165\n",
      "epoch [20/100], loss:1.0104\n",
      "epoch [21/100], loss:1.0064\n",
      "epoch [22/100], loss:0.9993\n",
      "epoch [23/100], loss:0.9854\n",
      "epoch [24/100], loss:0.9684\n",
      "epoch [25/100], loss:0.9531\n",
      "epoch [26/100], loss:0.9387\n",
      "epoch [27/100], loss:0.9242\n",
      "epoch [28/100], loss:0.9105\n",
      "epoch [29/100], loss:0.8988\n",
      "epoch [30/100], loss:0.8900\n",
      "epoch [31/100], loss:0.8840\n",
      "epoch [32/100], loss:0.8788\n",
      "epoch [33/100], loss:0.8710\n",
      "epoch [34/100], loss:0.8603\n",
      "epoch [35/100], loss:0.8494\n",
      "epoch [36/100], loss:0.8408\n",
      "epoch [37/100], loss:0.8342\n",
      "epoch [38/100], loss:0.8275\n",
      "epoch [39/100], loss:0.8201\n",
      "epoch [40/100], loss:0.8126\n",
      "epoch [41/100], loss:0.8060\n",
      "epoch [42/100], loss:0.7998\n",
      "epoch [43/100], loss:0.7930\n",
      "epoch [44/100], loss:0.7858\n",
      "epoch [45/100], loss:0.7787\n",
      "epoch [46/100], loss:0.7722\n",
      "epoch [47/100], loss:0.7663\n",
      "epoch [48/100], loss:0.7602\n",
      "epoch [49/100], loss:0.7537\n",
      "epoch [50/100], loss:0.7476\n",
      "epoch [51/100], loss:0.7421\n",
      "epoch [52/100], loss:0.7370\n",
      "epoch [53/100], loss:0.7320\n",
      "epoch [54/100], loss:0.7272\n",
      "epoch [55/100], loss:0.7222\n",
      "epoch [56/100], loss:0.7174\n",
      "epoch [57/100], loss:0.7127\n",
      "epoch [58/100], loss:0.7076\n",
      "epoch [59/100], loss:0.7024\n",
      "epoch [60/100], loss:0.6978\n",
      "epoch [61/100], loss:0.6935\n",
      "epoch [62/100], loss:0.6891\n",
      "epoch [63/100], loss:0.6851\n",
      "epoch [64/100], loss:0.6817\n",
      "epoch [65/100], loss:0.6781\n",
      "epoch [66/100], loss:0.6746\n",
      "epoch [67/100], loss:0.6715\n",
      "epoch [68/100], loss:0.6685\n",
      "epoch [69/100], loss:0.6657\n",
      "epoch [70/100], loss:0.6628\n",
      "epoch [71/100], loss:0.6598\n",
      "epoch [72/100], loss:0.6572\n",
      "epoch [73/100], loss:0.6546\n",
      "epoch [74/100], loss:0.6520\n",
      "epoch [75/100], loss:0.6497\n",
      "epoch [76/100], loss:0.6473\n",
      "epoch [77/100], loss:0.6449\n",
      "epoch [78/100], loss:0.6425\n",
      "epoch [79/100], loss:0.6401\n",
      "epoch [80/100], loss:0.6379\n",
      "epoch [81/100], loss:0.6356\n",
      "epoch [82/100], loss:0.6333\n",
      "epoch [83/100], loss:0.6310\n",
      "epoch [84/100], loss:0.6286\n",
      "epoch [85/100], loss:0.6264\n",
      "epoch [86/100], loss:0.6242\n",
      "epoch [87/100], loss:0.6220\n",
      "epoch [88/100], loss:0.6198\n",
      "epoch [89/100], loss:0.6177\n",
      "epoch [90/100], loss:0.6155\n",
      "epoch [91/100], loss:0.6134\n",
      "epoch [92/100], loss:0.6114\n",
      "epoch [93/100], loss:0.6093\n",
      "epoch [94/100], loss:0.6072\n",
      "epoch [95/100], loss:0.6052\n",
      "epoch [96/100], loss:0.6033\n",
      "epoch [97/100], loss:0.6013\n",
      "epoch [98/100], loss:0.5994\n",
      "epoch [99/100], loss:0.5975\n",
      "epoch [100/100], loss:0.5956\n",
      "1909\n",
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ConvTranspose2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "epoch [1/100], loss:2.2416\n",
      "epoch [2/100], loss:1.9544\n",
      "epoch [3/100], loss:1.6465\n",
      "epoch [4/100], loss:1.7160\n",
      "epoch [5/100], loss:1.4303\n",
      "epoch [6/100], loss:1.3519\n",
      "epoch [7/100], loss:1.3355\n",
      "epoch [8/100], loss:1.2913\n",
      "epoch [9/100], loss:1.2224\n",
      "epoch [10/100], loss:1.1560\n",
      "epoch [11/100], loss:1.1173\n",
      "epoch [12/100], loss:1.0910\n",
      "epoch [13/100], loss:1.0397\n",
      "epoch [14/100], loss:0.9858\n",
      "epoch [15/100], loss:0.9636\n",
      "epoch [16/100], loss:0.9612\n",
      "epoch [17/100], loss:0.9537\n",
      "epoch [18/100], loss:0.9331\n",
      "epoch [19/100], loss:0.9056\n",
      "epoch [20/100], loss:0.8812\n",
      "epoch [21/100], loss:0.8660\n",
      "epoch [22/100], loss:0.8573\n",
      "epoch [23/100], loss:0.8446\n",
      "epoch [24/100], loss:0.8240\n",
      "epoch [25/100], loss:0.8033\n",
      "epoch [26/100], loss:0.7889\n",
      "epoch [27/100], loss:0.7788\n",
      "epoch [28/100], loss:0.7677\n",
      "epoch [29/100], loss:0.7535\n",
      "epoch [30/100], loss:0.7391\n",
      "epoch [31/100], loss:0.7289\n",
      "epoch [32/100], loss:0.7230\n",
      "epoch [33/100], loss:0.7169\n",
      "epoch [34/100], loss:0.7081\n",
      "epoch [35/100], loss:0.6990\n",
      "epoch [36/100], loss:0.6912\n",
      "epoch [37/100], loss:0.6847\n",
      "epoch [38/100], loss:0.6805\n",
      "epoch [39/100], loss:0.6774\n",
      "epoch [40/100], loss:0.6716\n",
      "epoch [41/100], loss:0.6629\n",
      "epoch [42/100], loss:0.6553\n",
      "epoch [43/100], loss:0.6507\n",
      "epoch [44/100], loss:0.6471\n",
      "epoch [45/100], loss:0.6426\n",
      "epoch [46/100], loss:0.6369\n",
      "epoch [47/100], loss:0.6311\n",
      "epoch [48/100], loss:0.6264\n",
      "epoch [49/100], loss:0.6227\n",
      "epoch [50/100], loss:0.6188\n",
      "epoch [51/100], loss:0.6145\n",
      "epoch [52/100], loss:0.6104\n",
      "epoch [53/100], loss:0.6071\n",
      "epoch [54/100], loss:0.6040\n",
      "epoch [55/100], loss:0.6001\n",
      "epoch [56/100], loss:0.5958\n",
      "epoch [57/100], loss:0.5923\n",
      "epoch [58/100], loss:0.5896\n",
      "epoch [59/100], loss:0.5869\n",
      "epoch [60/100], loss:0.5837\n",
      "epoch [61/100], loss:0.5809\n",
      "epoch [62/100], loss:0.5785\n",
      "epoch [63/100], loss:0.5762\n",
      "epoch [64/100], loss:0.5737\n",
      "epoch [65/100], loss:0.5714\n",
      "epoch [66/100], loss:0.5695\n",
      "epoch [67/100], loss:0.5674\n",
      "epoch [68/100], loss:0.5654\n",
      "epoch [69/100], loss:0.5637\n",
      "epoch [70/100], loss:0.5618\n",
      "epoch [71/100], loss:0.5599\n",
      "epoch [72/100], loss:0.5584\n",
      "epoch [73/100], loss:0.5569\n",
      "epoch [74/100], loss:0.5553\n",
      "epoch [75/100], loss:0.5538\n",
      "epoch [76/100], loss:0.5526\n",
      "epoch [77/100], loss:0.5512\n",
      "epoch [78/100], loss:0.5501\n",
      "epoch [79/100], loss:0.5491\n",
      "epoch [80/100], loss:0.5480\n",
      "epoch [81/100], loss:0.5471\n",
      "epoch [82/100], loss:0.5462\n",
      "epoch [83/100], loss:0.5453\n",
      "epoch [84/100], loss:0.5444\n",
      "epoch [85/100], loss:0.5436\n",
      "epoch [86/100], loss:0.5429\n",
      "epoch [87/100], loss:0.5422\n",
      "epoch [88/100], loss:0.5414\n",
      "epoch [89/100], loss:0.5407\n",
      "epoch [90/100], loss:0.5401\n",
      "epoch [91/100], loss:0.5394\n",
      "epoch [92/100], loss:0.5388\n",
      "epoch [93/100], loss:0.5382\n",
      "epoch [94/100], loss:0.5376\n",
      "epoch [95/100], loss:0.5371\n",
      "epoch [96/100], loss:0.5365\n",
      "epoch [97/100], loss:0.5360\n",
      "epoch [98/100], loss:0.5355\n",
      "epoch [99/100], loss:0.5350\n",
      "epoch [100/100], loss:0.5346\n",
      "3221\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "# inicializa modelo, loss y optimizador\n",
    "k2=8\n",
    "k3=4\n",
    "for k1 in [8,16]:\n",
    "    num_epochs = 100\n",
    "    model = Autoencoder(k1,k2,k3)\n",
    "    print(model)\n",
    "    distance = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)\n",
    "    loss_list = [] \n",
    "    for epoch in range(num_epochs):\n",
    "        output = model(inputs,k1,8,4)\n",
    "        loss = distance(output, inputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "    np=0\n",
    "    for m in model.parameters():\n",
    "        np+=m.flatten().size()[0]\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3221\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
