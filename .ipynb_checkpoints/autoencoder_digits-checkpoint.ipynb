{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.models\n",
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "numeros = sklearn.datasets.load_digits()\n",
    "imagenes = numeros['images']  # Hay 1797 digitos representados en imagenes 8x8\n",
    "n_imagenes = len(imagenes)\n",
    "X = imagenes.copy()\n",
    "Y = numeros['target']\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.autograd.Variable(torch.Tensor(X).float()).unsqueeze(1)\n",
    "print(inputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# muestra algunos ejemplos\n",
    "\n",
    "n_items = inputs.data.size()[0]\n",
    "random_items = np.random.choice(np.arange(n_items), 5)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    item  = random_items[i]\n",
    "    plt.imshow(inputs[item][0].detach().numpy())\n",
    "    plt.title(Y[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1797, 1, 8, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normaliza\n",
    "mean = inputs.mean(dim=0)\n",
    "std = inputs.std(dim=0)\n",
    "std[std==0]=1.0\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    inputs[i] = (inputs[i])/std\n",
    "np.shape(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=3),\n",
    "            torch.nn.Conv2d(16,8,kernel_size=3),\n",
    "            torch.nn.Conv2d(8,4,kernel_size=3))\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(4,8,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(8,16,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(16,1,kernel_size=3))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 400\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/400], loss:2.2352\n",
      "epoch [2/400], loss:1.9329\n",
      "epoch [3/400], loss:1.5677\n",
      "epoch [4/400], loss:1.6641\n",
      "epoch [5/400], loss:1.3948\n",
      "epoch [6/400], loss:1.2977\n",
      "epoch [7/400], loss:1.2898\n",
      "epoch [8/400], loss:1.2385\n",
      "epoch [9/400], loss:1.1446\n",
      "epoch [10/400], loss:1.0684\n",
      "epoch [11/400], loss:1.0757\n",
      "epoch [12/400], loss:1.0755\n",
      "epoch [13/400], loss:1.0061\n",
      "epoch [14/400], loss:0.9678\n",
      "epoch [15/400], loss:0.9668\n",
      "epoch [16/400], loss:0.9658\n",
      "epoch [17/400], loss:0.9510\n",
      "epoch [18/400], loss:0.9273\n",
      "epoch [19/400], loss:0.9049\n",
      "epoch [20/400], loss:0.8912\n",
      "epoch [21/400], loss:0.8850\n",
      "epoch [22/400], loss:0.8784\n",
      "epoch [23/400], loss:0.8646\n",
      "epoch [24/400], loss:0.8458\n",
      "epoch [25/400], loss:0.8313\n",
      "epoch [26/400], loss:0.8229\n",
      "epoch [27/400], loss:0.8154\n",
      "epoch [28/400], loss:0.8050\n",
      "epoch [29/400], loss:0.7935\n",
      "epoch [30/400], loss:0.7850\n",
      "epoch [31/400], loss:0.7802\n",
      "epoch [32/400], loss:0.7744\n",
      "epoch [33/400], loss:0.7643\n",
      "epoch [34/400], loss:0.7536\n",
      "epoch [35/400], loss:0.7475\n",
      "epoch [36/400], loss:0.7445\n",
      "epoch [37/400], loss:0.7386\n",
      "epoch [38/400], loss:0.7294\n",
      "epoch [39/400], loss:0.7228\n",
      "epoch [40/400], loss:0.7186\n",
      "epoch [41/400], loss:0.7126\n",
      "epoch [42/400], loss:0.7067\n",
      "epoch [43/400], loss:0.7026\n",
      "epoch [44/400], loss:0.6978\n",
      "epoch [45/400], loss:0.6918\n",
      "epoch [46/400], loss:0.6869\n",
      "epoch [47/400], loss:0.6833\n",
      "epoch [48/400], loss:0.6786\n",
      "epoch [49/400], loss:0.6741\n",
      "epoch [50/400], loss:0.6714\n",
      "epoch [51/400], loss:0.6678\n",
      "epoch [52/400], loss:0.6635\n",
      "epoch [53/400], loss:0.6607\n",
      "epoch [54/400], loss:0.6571\n",
      "epoch [55/400], loss:0.6529\n",
      "epoch [56/400], loss:0.6501\n",
      "epoch [57/400], loss:0.6468\n",
      "epoch [58/400], loss:0.6440\n",
      "epoch [59/400], loss:0.6415\n",
      "epoch [60/400], loss:0.6383\n",
      "epoch [61/400], loss:0.6359\n",
      "epoch [62/400], loss:0.6336\n",
      "epoch [63/400], loss:0.6313\n",
      "epoch [64/400], loss:0.6293\n",
      "epoch [65/400], loss:0.6269\n",
      "epoch [66/400], loss:0.6253\n",
      "epoch [67/400], loss:0.6233\n",
      "epoch [68/400], loss:0.6213\n",
      "epoch [69/400], loss:0.6195\n",
      "epoch [70/400], loss:0.6174\n",
      "epoch [71/400], loss:0.6158\n",
      "epoch [72/400], loss:0.6140\n",
      "epoch [73/400], loss:0.6124\n",
      "epoch [74/400], loss:0.6108\n",
      "epoch [75/400], loss:0.6092\n",
      "epoch [76/400], loss:0.6077\n",
      "epoch [77/400], loss:0.6062\n",
      "epoch [78/400], loss:0.6047\n",
      "epoch [79/400], loss:0.6031\n",
      "epoch [80/400], loss:0.6016\n",
      "epoch [81/400], loss:0.6001\n",
      "epoch [82/400], loss:0.5987\n",
      "epoch [83/400], loss:0.5974\n",
      "epoch [84/400], loss:0.5960\n",
      "epoch [85/400], loss:0.5947\n",
      "epoch [86/400], loss:0.5934\n",
      "epoch [87/400], loss:0.5922\n",
      "epoch [88/400], loss:0.5909\n",
      "epoch [89/400], loss:0.5897\n",
      "epoch [90/400], loss:0.5886\n",
      "epoch [91/400], loss:0.5874\n",
      "epoch [92/400], loss:0.5863\n",
      "epoch [93/400], loss:0.5852\n",
      "epoch [94/400], loss:0.5842\n",
      "epoch [95/400], loss:0.5831\n",
      "epoch [96/400], loss:0.5821\n",
      "epoch [97/400], loss:0.5810\n",
      "epoch [98/400], loss:0.5800\n",
      "epoch [99/400], loss:0.5790\n",
      "epoch [100/400], loss:0.5781\n",
      "epoch [101/400], loss:0.5771\n",
      "epoch [102/400], loss:0.5762\n",
      "epoch [103/400], loss:0.5752\n",
      "epoch [104/400], loss:0.5743\n",
      "epoch [105/400], loss:0.5734\n",
      "epoch [106/400], loss:0.5725\n",
      "epoch [107/400], loss:0.5717\n",
      "epoch [108/400], loss:0.5708\n",
      "epoch [109/400], loss:0.5699\n",
      "epoch [110/400], loss:0.5691\n",
      "epoch [111/400], loss:0.5683\n",
      "epoch [112/400], loss:0.5675\n",
      "epoch [113/400], loss:0.5667\n",
      "epoch [114/400], loss:0.5659\n",
      "epoch [115/400], loss:0.5651\n",
      "epoch [116/400], loss:0.5643\n",
      "epoch [117/400], loss:0.5636\n",
      "epoch [118/400], loss:0.5629\n",
      "epoch [119/400], loss:0.5621\n",
      "epoch [120/400], loss:0.5614\n",
      "epoch [121/400], loss:0.5607\n",
      "epoch [122/400], loss:0.5601\n",
      "epoch [123/400], loss:0.5594\n",
      "epoch [124/400], loss:0.5587\n",
      "epoch [125/400], loss:0.5580\n",
      "epoch [126/400], loss:0.5574\n",
      "epoch [127/400], loss:0.5567\n",
      "epoch [128/400], loss:0.5561\n",
      "epoch [129/400], loss:0.5555\n",
      "epoch [130/400], loss:0.5548\n",
      "epoch [131/400], loss:0.5542\n",
      "epoch [132/400], loss:0.5536\n",
      "epoch [133/400], loss:0.5529\n",
      "epoch [134/400], loss:0.5523\n",
      "epoch [135/400], loss:0.5517\n",
      "epoch [136/400], loss:0.5511\n",
      "epoch [137/400], loss:0.5505\n",
      "epoch [138/400], loss:0.5499\n",
      "epoch [139/400], loss:0.5492\n",
      "epoch [140/400], loss:0.5486\n",
      "epoch [141/400], loss:0.5480\n",
      "epoch [142/400], loss:0.5474\n",
      "epoch [143/400], loss:0.5468\n",
      "epoch [144/400], loss:0.5463\n",
      "epoch [145/400], loss:0.5457\n",
      "epoch [146/400], loss:0.5451\n",
      "epoch [147/400], loss:0.5445\n",
      "epoch [148/400], loss:0.5439\n",
      "epoch [149/400], loss:0.5433\n",
      "epoch [150/400], loss:0.5428\n",
      "epoch [151/400], loss:0.5422\n",
      "epoch [152/400], loss:0.5416\n",
      "epoch [153/400], loss:0.5411\n",
      "epoch [154/400], loss:0.5405\n",
      "epoch [155/400], loss:0.5400\n",
      "epoch [156/400], loss:0.5394\n",
      "epoch [157/400], loss:0.5389\n",
      "epoch [158/400], loss:0.5383\n",
      "epoch [159/400], loss:0.5378\n",
      "epoch [160/400], loss:0.5372\n",
      "epoch [161/400], loss:0.5367\n",
      "epoch [162/400], loss:0.5362\n",
      "epoch [163/400], loss:0.5356\n",
      "epoch [164/400], loss:0.5351\n",
      "epoch [165/400], loss:0.5346\n",
      "epoch [166/400], loss:0.5341\n",
      "epoch [167/400], loss:0.5336\n",
      "epoch [168/400], loss:0.5331\n",
      "epoch [169/400], loss:0.5326\n",
      "epoch [170/400], loss:0.5321\n",
      "epoch [171/400], loss:0.5316\n",
      "epoch [172/400], loss:0.5311\n",
      "epoch [173/400], loss:0.5307\n",
      "epoch [174/400], loss:0.5302\n",
      "epoch [175/400], loss:0.5297\n",
      "epoch [176/400], loss:0.5293\n",
      "epoch [177/400], loss:0.5289\n",
      "epoch [178/400], loss:0.5284\n",
      "epoch [179/400], loss:0.5280\n",
      "epoch [180/400], loss:0.5276\n",
      "epoch [181/400], loss:0.5272\n",
      "epoch [182/400], loss:0.5268\n",
      "epoch [183/400], loss:0.5264\n",
      "epoch [184/400], loss:0.5260\n",
      "epoch [185/400], loss:0.5256\n",
      "epoch [186/400], loss:0.5253\n",
      "epoch [187/400], loss:0.5249\n",
      "epoch [188/400], loss:0.5245\n",
      "epoch [189/400], loss:0.5242\n",
      "epoch [190/400], loss:0.5238\n",
      "epoch [191/400], loss:0.5235\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestra los resultados de las cuatro capas de convolucion\n",
    "plt.figure(figsize=(14,14))\n",
    "offset = 100\n",
    "for i in range(5):\n",
    "    plt.subplot(5,5,i+1) #imagenes originales\n",
    "    plt.imshow((inputs[i+offset][0].detach().numpy()))\n",
    "    plt.title(Y[i+offset])\n",
    "    \n",
    "    j=0 # las imagenes reconstruidas por el autoencoder\n",
    "    plt.subplot(5,5,(i+1)+5*(j+1))\n",
    "    plt.imshow(x_transform[i+offset][0].detach().numpy())\n",
    "    \n",
    "    j=1 # una de las capas de la representacion latente\n",
    "    plt.subplot(5,5,(i+1)+5*(j+1))\n",
    "    plt.imshow(latent_space[i+offset][0].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
